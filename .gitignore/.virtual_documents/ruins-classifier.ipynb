


!pip install -q rasterio


## Imports

#Standard 
import os
import io
import base64
import shutil

#OpenAI
import openai
from kaggle_secrets import UserSecretsClient

#Google Earth Engine
import ee
import geemap

#Image processing
import cv2
import rasterio
from PIL import Image
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors

#Web/URL
import requests

#Data & Math
import numpy as np
import pandas as pd
from scipy.stats import randint

#Sklearn
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, IsolationForest
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay

#Pytorch & Tensorflow
import torch
import torch.nn as nn
from torchvision import models
import torchvision.transforms as transforms
from tensorflow.keras.applications.resnet50 import ResNet50

#Utilities
from tqdm import tqdm



## Dataset Paths

#Features
false_path = '/kaggle/input/resnet50-features/resnet_false_features_test.pt'
true_path = '/kaggle/input/resnet50-features/resnet_true_features_train.pt'
potential_path = '/kaggle/input/resnet50-features/resnet_potential_features_val.pt'

#Potential Ruins Tensor Paths
prpath = '/kaggle/input/tp-chunk-2/tile_chunk_tp_2.pt'
prpath2 = '/kaggle/input/potential-ruins/potential_ruins.pt'  

#Saved model weights
pretrained_weights_path = '/kaggle/input/resnet-trained-weights/resnet50_6ch_feature_extractor.pth'

#Generate token
ee.Authenticate(auth_mode='notebook', force=True)


#OpenAI Setup
user_secrets = UserSecretsClient()
secret_value_0 = user_secrets.get_secret("openAI_key")
os.environ["OPENAI_API_KEY"] = str(secret_value_0)
client = openai.OpenAI()


##Tile Loading Functions

#from previous notebook, redefined here for visualizations & plotting

def generate_ndvi_tile(lat, lon, step = .02):
    """
    Normalized Difference Vegetation Index
    Normalized Difference of Near Infrared (NIR) and Red bands
    NDVI (vegetation index): (NIR - RED)/(NIR + RED)
    lat: latitude, float
    lon: longitude, float
    step: designates tile area, float
 
    """
    ee.Authenticate()
    ee.Initialize()

    #Defining region
    region = ee.Geometry.Rectangle([lon - step, lat - step, lon + step, lat + step])

    #LANDSAT data
    collection = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \
        .filterBounds(region) \
        .filterDate('2022-01-01', '2022-12-31') \
        .sort('CLOUD_COVER') \
        .first()

    #Scaling
    def scale_bands(img):
        return img.select(
                    ['SR_B4', 'SR_B5']) \
                  .multiply(0.0000275).add(-0.2) \
                  .rename(['Red', 'NIR'])

    image = scale_bands(collection)

    #calculate NDVI, clipping and producing image
    ndvi = image.normalizedDifference(['NIR', 'Red']).rename('NDVI')
    ndvi = ndvi.clip(region)
    ndvi_array = ndvi.sampleRectangle(region=region, defaultValue=0).get('NDVI').getInfo()
    ndvi_np = np.array(ndvi_array).astype(np.float32).copy()
    ndvi_norm = np.clip((ndvi_np + 1) / 2, 0, 1)
    image = Image.fromarray((ndvi_norm * 255).astype(np.uint8))

    return image

    
def generate_ndbi_tile(lat, lon, step = .02):
    """
    Normalized Difference Built-Up Index
    Normalized Difference of Near Infrared (NIR) and Showt-Wave Infrared (SWIR)
    NDVI (Built-Up Index): (SWIR - NIR) / (SWIR + NIR)
    lat: latitude, float
    lon: longitude, float
    step: designates tile area, float
    """
    ee.Initialize()

    #Defining region
    region = ee.Geometry.Rectangle([lon - step, lat - step, lon + step, lat + step])

    #LANDSAT Data
    landsat = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \
    .filterBounds(region) \
    .filterDate('2020-01-01', '2020-12-31') \
    .filterMetadata('CLOUD_COVER', 'less_than', 50) \
    .sort('CLOUD_COVER') \
    .first()

    #Scaling
    def scale_bands(img):
        return img.select(
                    ['SR_B6', 'SR_B5']) \
                  .multiply(0.0000275).add(-0.2) \
                  .rename(['SWIR', 'NIR'])
    
    
    
    image = scale_bands(landsat)

    #Calculating Index
    ndbi = image.normalizedDifference(['SWIR', 'NIR']).rename('NDBI')

    #Clipping index values to the region
    ndbi = ndbi.clip(region).unmask(0).reproject(crs='EPSG:4326', scale=30)
    
    #To array + resized
    ndbi_array = ndbi.sampleRectangle(region=region, defaultValue=0).get('NDBI').getInfo()
    ndbi_np = np.array(ndbi_array).astype(np.float32).copy()
    ndbi_norm = np.clip((ndbi_np + 1) / 2, 0, 1)

    img = Image.fromarray((ndbi_norm * 255).astype(np.uint8))

    return img



def generate_rgb_tile(lat,lon,step = 0.02, authenticate=False):
    """
    Standard Satellite Imagery 
    lat: latitude, float
    lon: longitude, float
    step: designates tile area, float
    """

    #Optional authentication to generate a session token
    if authenticate:
        ee.Authenticate(auth_mode='notebook', force=True)
    else:
        ee.Authenticate()
    ee.Initialize()

    #Defining region
    region = ee.Geometry.Rectangle([lon-step, lat-step, lon+step, lat+step])

    #Copernicus data
    sentinel = ee.ImageCollection("COPERNICUS/S2_SR_HARMONIZED") \
        .filterBounds(region) \
        .filterDate('2022-01-01', '2022-12-31') \
        .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 10)) \
        .median() \
        .clip(region)
    
    #URL to get RGB
    url = sentinel.getThumbURL({
        'bands': ['B4', 'B3', 'B2'],  # RGB bands
        'region': region,
        'dimensions': 512,
        'min': 0,
        'max': 3000,
        'format': 'png'
    })

    #Get image, return image and region
    
    response = requests.get(url)
    image_pil = Image.open(io.BytesIO(response.content))
    geo_bounds = {'lat_min': lat-.02, 'lat_max': lat+.02, 'lon_min': lon-.02, 'lon_max':lon+.02}
    return image_pil, geo_bounds
    

def generate_elevation_tile(lat,lon,step = 0.02):
    """
    Elevation in Meters, Topograchic Data from the USGS
    lat: latitude, float
    lon: longitude, float
    step: designates tile area, float
    """
    #Defining region
    aoi = ee.Geometry.BBox(lon-step, lat-step, lon+step, lat+step)
    
    #Specifying dataset
    srtm = ee.Image("USGS/SRTMGL1_003").clip(aoi)
    out_dem = "dem.tif"
    geemap.ee_export_image(
        srtm,
        filename=out_dem,
        scale=30,
        region=aoi,
        file_per_band=False
    )
    
    with rasterio.open(out_dem) as src:
        elevation_array = src.read(1)
        
    #Normalizing
    array_min = elevation_array.min()
    array_ptp = elevation_array.ptp() + 1e-8  # Zeros handling
    normalized = (elevation_array - array_min) / array_ptp

    image = Image.fromarray((normalized * 255).astype(np.uint8))
    
    return image


## K-Means Clustering to sort the positive known ruins data

#Loading
data = torch.load(false_path, weights_only=False)
data2 = torch.load(true_path, weights_only=False)
data3 = torch.load(potential_path, weights_only = False)

false_features,false_labels,false_coords = data['features'],data['labels'],data['coords']
true_features,true_labels,true_coords = data2['features'],data2['labels'],data2['coords']
potential_features, potential_coords = data3['features'], data3['coords']



X = np.stack(true_features) #[N, 2048]


cluster = KMeans(n_clusters=2).fit(X)
label = cluster.labels_

#Creating dataframe of features with clusters
feat_frame = pd.DataFrame(true_features,columns=[f'feature:{i}'for i in range(len(true_features[0]))])
df_cluster = pd.DataFrame(true_coords, columns = ['lat','lon'])
df_cluster["cluster"] = label
df_cluster = pd.concat([df_cluster,feat_frame],axis=1)


#Sanitation Check
torch.isnan(potential_features).any()


## RGB Images of the two tiles closest in features to each cluster center


for i in range(len(cluster.cluster_centers_)):
    center = cluster.cluster_centers_[i]
    df_i = df_cluster[df_cluster['cluster']==i].reset_index(drop=True)
    features_0 = np.stack(df_i.iloc[:,3:2051].values)
    distances_0 = np.linalg.norm(features_0 - center, axis=1)
    closest_idx_0 = np.argmin(distances_0)
    closest_point_0 = df_i.iloc[closest_idx_0][['lat', 'lon']]
    print(f"Closest point to center {i}: {closest_point_0.values}")
    c,_ = generate_rgb_tile(closest_point_0.values[0],closest_point_0.values[1])
    plt.imshow(c)
    plt.show()


## Plots of clusters with their centers

cluster_1 = df_cluster[df_cluster['cluster']==0][['lat','lon']]
cluster_2 = df_cluster[df_cluster['cluster']==1][['lat','lon']]

plt.scatter(cluster_1['lon'],cluster_1['lat'])
plt.plot(-68.71,-10.9249,color='r',marker='*')
plt.title('Cluster 0 Geography')
plt.xlabel('Longitude')
plt.ylabel('Latitude')
plt.show()

plt.title('Cluster 1 Geography')
plt.xlabel('Longitude')
plt.ylabel('Latitude')
plt.scatter(cluster_2['lon'],cluster_2['lat'])
plt.scatter(-67.201,-9.2107,color='r',marker='*')
plt.show()


## Each Cluster Plotted Together, with the ruin candidate

plt.figure(figsize=(10, 6))

scatter = plt.scatter(
    df_cluster["lon"],
    df_cluster["lat"],
    c=df_cluster["cluster"],
)

#Adding in final submission tile coordinates: 
plt.scatter(-64.69699999999995,-5.392500000000001,color='red')
plt.title("K-Means Clustering of Ruins in the Amazon Rainforest")
plt.xlabel("Longitude")
plt.ylabel("Latitude")
plt.grid(True)
plt.show()





## Train & Predict Functions for Random Forest
def train_model(X, y, param_grid):
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_scaled, y)
    return model, scaler
    
def predict_anomalies(model, scaler, X):
    X_scaled = scaler.fit_transform(X)
    probs = model.predict_proba(X_scaled)
    return probs[:, 1]


## Picking the top 600 points closest to the forested cluster center (in feature distance)

#Designating cluster
target_cluster = 0
df_target = df_cluster[df_cluster['cluster'] == target_cluster].reset_index(drop=True)

#Feature columns
feature_cols = [col for col in df_target.columns if col.startswith('feat')]
features = df_target[feature_cols].values  #(num_points_in_cluster, num_features)

#Cluster Center
center = cluster.cluster_centers_[target_cluster]

#Calculating Euclidean distances from each point to the cluster center
distances = np.linalg.norm(features - center, axis=1)

#Indices of the top 600 closest points
top_600_idx = np.argsort(distances)[:600]

#Extracting top 600 from ids
top_600_points = df_target.iloc[top_600_idx][feature_cols].reset_index(drop=True)

print(f"Top 600 points generated with shape: {top_600_points.shape}")


## Sanitation Checks + Dataset Construction

#Creating dataframes + labels
top_600_points['label'] = 1
true_positives = top_600_points
true_negatives = pd.DataFrame(false_features, columns = [f"feature:{i}" for i in range(len(false_features[0]))])
true_negatives['label'] = false_labels
neg_coord =  pd.DataFrame(false_coords,columns = ['lat','lon'])
true_negatives = pd.concat([true_negatives,neg_coord],axis=1)
print(f"Nulls Check: {true_negatives.isna().any().any()}")

#Tiles of interest
potential = pd.DataFrame(potential_features, columns = [f"feature:{i}" for i in range(len(potential_features[0]))])
print(f"Nulls Check: {potential.isna().any().any()}")
potential_coord =  pd.DataFrame(potential_coords,columns = ['lat','lon'])
print(f"Nulls Check: {potential_coord.isna().any().any()}")
potential = pd.concat([potential.reset_index(drop=True), potential_coord.reset_index(drop=True)], axis=1)
print(f"Nulls Check: {potential.isna().any().any()}")


dataset = pd.concat((true_positives, true_negatives)).reset_index(drop=True)
print(f"Dataset constructed with shape: {dataset.shape}") #N samples x M (features/lat/lon/label)


## Random Forest Inputs + PCA

X = np.array(dataset[feature_cols])
y = np.array(dataset['label'])

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42, shuffle = True)
print(f"Train/Test split complete with X_train shape: {X_train.shape}")
X_train = np.stack(X_train)
X_test = np.stack(X_test)
y_train = np.stack(y_train)
y_test = np.stack(y_test)



#PCA
pca = PCA(n_components=500)

X_train_pca = pca.fit_transform(X_train)
X_test_pca = pca.fit_transform(X_test)
print(f"PCA Complete with X_train shape: {X_train_pca.shape}")



#Train & Testing & Confusion Matrix
param_grid = []
model, scaler = train_model(X_train_pca, y_train, param_grid)
y_pred = model.predict(X_test_pca)

cm = confusion_matrix(y_test,y_pred)
display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])


print(f"Test accuracy: {accuracy_score(y_test, y_pred):.4f}")
display.plot(cmap='Blues')


#Predictions for the sites of interest

X_explore = np.array(potential[feature_cols])
pca_feats = pca.fit_transform(np.concatenate((X_explore,X_train)))
potential_feats = pca_feats[:82]
scaler = StandardScaler()
preds = predict_anomalies(model,scaler,potential_feats)


print(preds)





## Isolation Forest Functions

#Loading image and divide into patches
def get_patches_from_array(img, patch_size=(64, 64), step=32):
    """
    Breaking image up into smaller patches. 
    The anomaly will be the patch that stands out the most in each image.
    """
    patches = []
    positions = []
    
    c,h,w = img.shape #Channel, Height, Width
    patch_h, patch_w = patch_size

    
    for y in range(0, h - patch_h + 1, step):
        for x in range(0, w - patch_w + 1, step):
            
            patch = img[:, y:y+patch_h, x:x+patch_w]  #shape (C, H, W) 
            patch = np.transpose(patch, (1, 2, 0))    #convert to (H, W, C)
            
            patches.append(patch)
            positions.append((x, y))

    return np.array(patches), positions, (h, w)


#Isolation Forest


#Get anomaly scores
def detect_anomalies(features):
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(features)

    #Setting contamination low for accurate ruin simulation
    iso_forest = IsolationForest(contamination=0.025, random_state=42)
    scores = iso_forest.fit_predict(X_scaled)
    return scores



def build_feature_extractor(state_dict_path, input_channels=6, device='cpu'):
    """
    Sets up the resnet structure, removing final classification layer and resizing inputs
    """
    model = models.resnet50(pretrained=False)

    #Modifying first layer for new input channels size
    model.conv1 = nn.Conv2d(input_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)
    

    in_features = model.fc.in_features
    model.fc = nn.Linear(in_features, 2) 

    #Loading weights
    state_dict = torch.load(state_dict_path, map_location=device)
    model.load_state_dict(state_dict)

    #Strip off classifier to make it a feature extractor
    feature_extractor = nn.Sequential(*list(model.children())[:-1])  #No final classifier
    feature_extractor = feature_extractor.to(device)
    feature_extractor.eval()

    return feature_extractor



def build_anomalies(feat, geo_bounds, patch_size=(64, 64), step=32, contamination=0.0025, device='cpu'):
    """
    Detects and matches the anomalies from the score matrix to lat/lon position using the coordinate ranges
    and features given.
    
    """
    
    #Get Dimensions
    _, img_h, img_w = feat.shape
    
    #Get Patches
    patches, positions, _ = get_patches_from_array(feat, patch_size=patch_size, step=step)
    
    #To Tensor
    patch_tensor = torch.tensor(patches).permute(0, 3, 1, 2).float()  #[N, C, H, W]

    #Build extractor
    feature_extractor = build_feature_extractor(pretrained_weights_path, device=device)
    patch_tensor = patch_tensor.to(device)

    #Extract features
    with torch.no_grad():
        feats = feature_extractor(patch_tensor)         #[N, 2048, 1, 1]
        feats = feats.view(feats.size(0), -1).cpu().numpy()  #[N, 2048]

    scores = detect_anomalies(feats)

    #Matching scores to coordinates
    anomalies = []
    for i, pred in enumerate(scores):
        if pred == -1:
            x, y = positions[i] 

            #Using pixel centers for lat/lon
            pixel_x_center = x + patch_size[0]//2
            pixel_y_center = y + patch_size[1]//2

            lon = geo_bounds['lon_min'] + (pixel_x_center/img_w)*(geo_bounds['lon_max'] - geo_bounds['lon_min'])
            lat = geo_bounds['lat_max'] - (pixel_y_center/img_h)*(geo_bounds['lat_max'] - geo_bounds['lat_min'])

            anomalies.append({
                'lat': lat,
                'lon': lon,
                'score': -1,
                'radius_m': step
            })

    return anomalies


def plot_array_with_anomalies(array, geo_bounds, anomalies, title="Data", cmap="terrain", label="Value"):
    """
    Generic plotter for single band arrays with anomalies
    
    """
    lat_min = geo_bounds['lat_min']
    lat_max = geo_bounds['lat_max']
    lon_min = geo_bounds['lon_min']
    lon_max = geo_bounds['lon_max']

    H, W = array.shape

    plt.figure(figsize=(6, 6))
    plt.imshow(array, cmap=cmap, origin="upper")  
    
    for anomaly in anomalies:
        lat = anomaly['lat']
        lon = anomaly['lon']

        #Converting lat/lon to pixel coords
        x = (lon - lon_min)/(lon_max - lon_min) * W
        y = (lat_max - lat)/(lat_max - lat_min) * H  

        plt.plot(x, y, 'ro', markersize=5)
        plt.gca().add_patch(
            plt.Circle(
                (x, y),
                anomaly['radius_m'] * H / 4440,  
                color='red',
                fill=False,
                linewidth=1
            )
        )

    plt.colorbar(label=label)
    
    plt.title(f"{title} with Anomalies")
    plt.xlabel("Longitude (approx. px)")
    plt.ylabel("Latitude (approx. px)")
    plt.show()



def visualize_anomalies(image_pil, geo_bounds, anomalies, patch_size=(64, 64), save_path=None, show=True):
    """
    Visualizes anomaly patch with satellite imageing, showing the image + outlined patch
    geo_bounds: dictionary of the image bounding box coordinates
    image_pil: imput pil image
    
    """
    #Creating cv2 image object, getting dimensions
    img_cv2 = cv2.cvtColor(np.array(image_pil), cv2.COLOR_RGB2BGR)
    img_h, img_w = img_cv2.shape[:2]

    #Drawing anomaly bounding boxes
    for anomaly in anomalies:
        
        #Converting lat/lon back to pixel
        lat, lon = anomaly['lat'], anomaly['lon']
        x = int(((lon - geo_bounds['lon_min'])/(geo_bounds['lon_max'] - geo_bounds['lon_min']))*img_w)
        y = int(((geo_bounds['lat_max'] - lat)/(geo_bounds['lat_max'] - geo_bounds['lat_min']))*img_h)
        top_left = (x - patch_size[0]//2, y - patch_size[1]//2)
        bottom_right = (x + patch_size[0]//2, y + patch_size[1]//2)
        cv2.rectangle(img_cv2, top_left, bottom_right, (0, 0, 255), 2)

    if show:
        plt.imshow(cv2.cvtColor(img_cv2, cv2.COLOR_BGR2RGB))
        
        plt.axis('off')
        plt.show()
        
    if save_path:
        cv2.imwrite(save_path, img_cv2)
  



## Potential Ruins Tensors Loading

prp = torch.load(prpath,weights_only=False)

#Dataframe to fill
df = pd.DataFrame({'lat':[],'lon':[]})

#Converting coords to dataframe
for i in prp['coords']:
    for j in i:
        dftemp = pd.DataFrame({'lat':[j['lat']],'lon':[j['lon']]})
        df = pd.concat([df,dftemp])

      
prp2 = torch.load(prpath2,weights_only=False)

#Dataframe to fill
df2 = pd.DataFrame({'lat':[],'lon':[]})

#Converting coords to dataframe
for i in prp2['coords']:
    for j in i:
        dftemp2 = pd.DataFrame({'lat':[j['lat']],'lon':[j['lon']]})
        df2 = pd.concat([df2,dftemp2])


#Site candidate location is 0
total_coord_df = pd.concat([df2,df]).reset_index(drop=True).iloc[0]

raw_batch = torch.cat((torch.cat(prp2['batches']),torch.cat(prp['batches']))).numpy()[0]
print(raw_batch.shape,total_coord_df.shape)





!pip install openai


#ChatGPT Query Functions

def image_to_data_url(image):
    if isinstance(image, np.ndarray):
        if image.dtype != np.uint8:
            image = (255 * (image - np.min(image)) / (np.ptp(image) + 1e-8)).astype(np.uint8)
        image = Image.fromarray(image)

    buffered = io.BytesIO()
    image.save(buffered, format="JPEG")
    img_base64 = base64.b64encode(buffered.getvalue()).decode("utf-8")
    return f"data:image/jpeg;base64,{img_base64}"


def query_chatgpt_with_images(prompt, images, model="gpt-4o"):
    
    image_messages = []
    for image in images:
        buffered = io.BytesIO()
        image.save(buffered, format="JPEG")
        img_base64 = base64.b64encode(buffered.getvalue()).decode("utf-8")
        img_data_url = f"data:image/jpeg;base64,{img_base64}"
        image_messages.append({
            "type": "image_url",
            "image_url": {"url": img_data_url}
        })

    messages = [
        {
            "role": "user",
            "content": [
                {"type": "text", "text": prompt},
                *image_messages
            ],
        }
    ]

    response = client.chat.completions.create(
        model=model,
        messages=messages,
        max_tokens=1000,
    )

    
    return response.choices[0].message.content
    


## Final Candidate Evidence


#Chosen final candidate based on  RFC score + anomaly reproducibility + prompt response
lat, lon = total_coord_df['lat'], total_coord_df['lon']
   
#Building anomalies + rgb tile
image_pil, geo_bounds = generate_rgb_tile(lat,lon)
anomalies = build_anomalies(raw_batch,geo_bounds)

#Generating images and arrays
elev_array = generate_elevation_tile(lat,lon)
ndvi_pil = generate_ndvi_tile(lat,lon)
ndbi_pil = generate_ndbi_tile(lat,lon)
ndvi_array = np.asarray(ndvi_pil)
ndbi_array = np.asarray(ndbi_pil)
elevation_array = np.asarray(elev_array)


#Plotting & Visualizing in all image types
print(f"Anomaly: {anomalies}")
visualize_anomalies(image_pil,geo_bounds,anomalies)    
plot_array_with_anomalies(np.asarray(elevation_array),geo_bounds,anomalies,title='ELEVATION')
plot_array_with_anomalies(np.asarray(ndvi_pil),geo_bounds,anomalies,title='NDVI')
plot_array_with_anomalies(np.asarray(ndbi_pil),geo_bounds,anomalies,title='NDBI')

    
    
#Asking ChatGPT
images = [image_pil,elev_array,ndvi_pil,ndbi_pil]
prompt = """
        Given the four types of images in order of RGB, elevation, NDVI, NDBI data, please advise on the likelihood of the crescent shape in the middle
        being a ruin. This image was taken in the amazon rainforest. This site is located in the Amazonas region of the Western Brazilian Amazon. This part of Amazonas is home to Panoan-speaking peoples (like the Marúbo and Matsés) and Arawá language families, which are relatively isolated and thus potentially culturally conservative — preserving traits from pre-Columbian societies.Sites near the Juruá and Purus rivers show extensive terra preta, evidence of intensive ancient habitation and soil management.
        When plotted on a scale the measurements are as follows (roughly): Elevation: Lower than surroundings, crescent patch near 0 while surroundings are 100+.
        NDVI: Lower than surroundings. Surroundings are 230-250, patch is 200-220. NDBI: FLuctuates. The patch itself is 85-95 with immediate surroundings 65-70 and farther surroundings 70-80.
        Additionally, please cite one historical text that supports the possibility of a ruin at these coordinates (-5.392500000000001,-64.69699999999995). Explore cultural history of the area to give a time frame for when this site was from (if it is indeed ruins).
        """    
response = query_chatgpt_with_images(prompt, images, model="gpt-4o")
print(response)
